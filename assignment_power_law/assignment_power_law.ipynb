{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Assignment â€” Power Law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power law distribution\n",
    "\n",
    "The PDF of the Power law distribution is \n",
    "\n",
    "$$ p(x) = Cx^{-\\alpha},$$ \n",
    "\n",
    "where $C$ is normalization constant and $\\alpha>1$ is called as exponent of the distribution. \n",
    "\n",
    "From the lecture we know that \n",
    "\n",
    "$$C = \\frac{\\alpha - 1}{x_{\\text{min}}^{-\\alpha + 1}}.$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "29aeb24a4abc6b58d9d9e4b6e8b65ae5",
     "grade": false,
     "grade_id": "cell-82ac9cd229c7e4c3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def power_law_pdf(x, alpha, x_min):\n",
    "    '''Calculate probability density function of Power law'''\n",
    "    C = (alpha - 1) / x_min ** (1 - alpha)\n",
    "    return C * x ** (-alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try to generate observations from Power law random variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1. Power law CDF (1 point)\n",
    "\n",
    "The first step is to derive CDF of Powel law: $F(x) = P(X \\leq x)$\n",
    "\n",
    "$$F(x) = 1 - \\int_{x}^\\infty p(t) dt.$$\n",
    "\n",
    "Take the integral, derive CDF analytically and write a function `power_law_cdf` with parameters `x`, `alpha` and `x_min`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "64846d64d12563618e5e3dc8f797d93e",
     "grade": false,
     "grade_id": "cell-6f13f381ac36b5a0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def power_law_cdf(x, alpha=3.5, x_min=1):\n",
    "    '''Calculate cumulative distribution function of Power law'''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "46e775c5664403099a362ef093f46cf9",
     "grade": true,
     "grade_id": "cell-ff181adf4906cc61",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''Check that CDF returns the correct output for several inputs'''\n",
    "assert power_law_cdf(2, 2, 1) == 0.5\n",
    "assert power_law_cdf(10, 2, 1) == 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2. Power law PPF (1 point)\n",
    "\n",
    "Let $X \\sim \\text{Power law}$. Next, define a random variable $R$, s.t. $R = F(X)$, so $R$ will be uniformly distributed on interval [0, 1] ([proof](https://en.wikipedia.org/wiki/Probability_integral_transform#Proof)). Good thing here is that we easily can generate uniformly distributed pseudorandom numbers. Let us find an expression for $x = F^{-1}(r)$, where $r$ is an observation from uniform distrubution on interval [0, 1]. \n",
    "\n",
    "Find an analytical form of $F^{-1}(r)$ and write a function `power_law_ppf` (percent point function) with parameters `r`, `alpha` and `x_min`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ede087d86b8e2ae0390093ab6547832e",
     "grade": false,
     "grade_id": "cell-345dcb7670848dca",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def power_law_ppf(r, alpha=3.5, x_min=1):\n",
    "    '''Calculate percent point value of Power law'''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "86f2c8865c0a723f42491b07c7623b56",
     "grade": true,
     "grade_id": "cell-dd7b6d2127b66790",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''Check that PPF returns the correct output for several inputs'''\n",
    "assert round(power_law_ppf(0.5, 2, 1), 10) == 2\n",
    "assert round(power_law_ppf(0.9, 2, 1), 10) == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can generate observation from Power law distribution as follows:\n",
    "1. Generate observation from uniform distribution on interval [0, 1]\n",
    "2. Calculate PPF value of given observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da9742d99f0de52fa460c5dba1a212ac",
     "grade": false,
     "grade_id": "cell-dcbd4ca48c75334f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def power_law_generate(n, alpha=3.5, x_min=1, random_seed=1):\n",
    "    '''Generate observation from Power law distribution'''\n",
    "    np.random.seed(random_seed)\n",
    "    uni_sample = np.random.uniform(0, 1, n)\n",
    "    return power_law_ppf(uni_sample, alpha, x_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the histogram of the generated sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 3.5\n",
    "x_min = 1\n",
    "x_train = power_law_generate(1000, alpha, x_min, 0)\n",
    "x_space = np.linspace(1, 15, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x_train, bins=200, density=True)\n",
    "plt.plot(x_space, power_law_pdf(x_space, alpha, x_min), label='Theoretical PDF')\n",
    "plt.legend()\n",
    "plt.xlim(0, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same histogram in log-log scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x_train, bins=200, density=True)\n",
    "plt.plot(x_space, power_law_pdf(x_space, alpha, x_min), label='Theoretical PDF')\n",
    "plt.legend()\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3. Estimation $\\alpha$ with linear binning (2 points)\n",
    "\n",
    "Given observations from Power law distribution, try to estimate $\\alpha$. The easiest way is to draw an empirical PDF with linear binning in log-log scale and apply linear regression. For linear binning we fix each bin of empirical PDF in the same size.\n",
    "\n",
    "Write a function `alpha_lin_bins` that returns an estimated $\\alpha$.\n",
    "\n",
    "*Hints:*\n",
    "1. *Take the logarithm of both sides of PDF $p(x) = Cx^{-\\alpha}$*\n",
    "2. *To estimate $p(x)$ use an empirical PDF: `np.histogram(x, bins=1000, density=True)`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ab07bbc856e5fa764da3970fff0b112",
     "grade": false,
     "grade_id": "cell-dd9d0b10b1d7511a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def alpha_lin_bins(x_train):\n",
    "    '''Estimate alpha using linear regression'''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "550e1ffcb79a1a8696595fe5485a31e8",
     "grade": true,
     "grade_id": "cell-533019972c37acab",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''Check estimations for different inputs'''\n",
    "assert 2 < alpha_lin_bins(power_law_generate(20000, alpha=3.5)) < 5\n",
    "assert 6 < alpha_lin_bins(power_law_generate(20000, alpha=10)) < 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us draw the estimated PDF with linear binning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, x_min = 7, 1\n",
    "x_train = power_law_generate(10000, alpha, x_min)\n",
    "hist, bin_edges = np.histogram(x_train, bins=1000, density=True)\n",
    "bin_centers = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "idx = hist > 0\n",
    "plt.scatter(bin_centers[idx], hist[idx], s=5)\n",
    "x_space = np.linspace(bin_centers[idx].min(), bin_centers[idx].max(), 100)\n",
    "hat_alpha = alpha_lin_bins(x_train)\n",
    "plt.plot(\n",
    "    x_space, \n",
    "    power_law_pdf(x_space, hat_alpha, 1), \n",
    "    color='tab:orange',\n",
    "    label='Estimated PDF')\n",
    "plt.legend()\n",
    "plt.title('Truth $\\\\alpha = {}$, estimated $\\\\hat\\\\alpha = {:.2f}$'.format(alpha, hat_alpha[0]))\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4. Estimation $\\alpha$ with logarithmic binning (2 points)\n",
    "\n",
    "As we see the estimation with linear binning is noticeably inaccurate. Why do you think? _Hint: fat tail_. Let us try to apply logarithmic binning. For logarithmic binning we let the bin sizes increase with the value, making sure that each bin has a comparable number of observations.\n",
    "\n",
    "Write a function `alpha_log_bins` that returns an estimated $\\alpha$.\n",
    "\n",
    "*Hint: use `np.logspace(0, np.log10(x_train.max()), 20)` to generate an increasing logarithmic sequence of 20 bins.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e59115b5ca1dcf04f8f3d41f671cc376",
     "grade": false,
     "grade_id": "cell-ca7ba595a15b8a6e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def alpha_log_bins(x_train):\n",
    "    '''Estimate alpha using linear regression'''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4378d953c91298ea0114838aa60d262c",
     "grade": true,
     "grade_id": "cell-6cb818fef2527ad9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''Check estimations for different inputs'''\n",
    "assert 3.4 < alpha_log_bins(power_law_generate(20000, alpha=3.5)) < 3.6\n",
    "assert 9.9 < alpha_log_bins(power_law_generate(20000, alpha=10)) < 10.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us draw the estimated PDF with log binning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.logspace(0, np.log10(x_train.max()), 20)\n",
    "hist, bin_edges = np.histogram(x_train, bins=bins, density=True)\n",
    "bin_centers = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "hat_alpha = alpha_log_bins(x_train)\n",
    "idx = hist > 0\n",
    "plt.scatter(bin_centers[idx], hist[idx])\n",
    "x_space = np.linspace(bin_centers[idx].min(), bin_centers[idx].max(), 100)\n",
    "plt.plot(\n",
    "    x_space, \n",
    "    power_law_pdf(x_space, hat_alpha, 1), \n",
    "    color='tab:orange',\n",
    "    label='Estimated PDF')\n",
    "plt.legend()\n",
    "plt.title('Truth $\\\\alpha = {}$, estimated $\\\\hat\\\\alpha = {:.4f}$'.format(alpha, hat_alpha[0]))\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NetworkX quick start\n",
    "\n",
    "NetworkX is a Python package that we will use for network analysis. First of all, let us check that we use the version 2.5 of NetworkX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "assert nx.__version__ == '2.5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have another version, please reinstall the package \n",
    "\n",
    "```\n",
    "pip uninstall networkx\n",
    "pip install networkx==2.5\n",
    "```\n",
    "\n",
    "Next, create an empty graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create edges one-by-one. For example, create nodes 1, 2 and edge between them. Repeat for nodes 2, 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_edge(1, 2)\n",
    "G.add_edge(2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can create edges from list of edges. Create edges (2, 4), (2, 5) and (2, 6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_edges_from([(2, 4), (2, 5), (2, 6)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us draw the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a list of edges and nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(G.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(G.edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get nodes degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of pairs of the form (node: degree)\n",
    "G.degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to clear the graph use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us read a graph from a file with a list of edges. Create a new file, and then read it via NetworkX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('edges.txt', 'w') as edges_file:\n",
    "    edges_file.writelines(\n",
    "        '''\n",
    "        1 2\n",
    "        2 3\n",
    "        2 4\n",
    "        2 5\n",
    "        2 6\n",
    "        '''\n",
    "    )\n",
    "\n",
    "G = nx.read_edgelist('edges.txt')\n",
    "nx.draw(G, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we can read an adjacency matrix using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('adjacency.txt', 'w') as edges_file:\n",
    "    edges_file.writelines(\n",
    "        '''\n",
    "        0 1 0 0 0 0\n",
    "        1 0 1 1 1 1\n",
    "        0 1 0 0 0 0\n",
    "        0 1 0 0 0 0\n",
    "        0 1 0 0 0 0\n",
    "        0 1 0 0 0 0\n",
    "        '''\n",
    "    )\n",
    "\n",
    "A = np.loadtxt('adjacency.txt')\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_numpy_array(A)\n",
    "nx.draw(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute some graph statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.radius(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.diameter(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.average_shortest_path_length(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read about other features of NetworkX here https://networkx.github.io/documentation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Real Distributions\n",
    "\n",
    "Let us consider [fb_Princeton.txt](https://raw.githubusercontent.com/vpozdnyakov/network_science_assignments/master/assignment_power_law/fb_Princeton.txt): Princeton Facebook friendship network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5. Descriptive statistics of a network (2 points)\n",
    "\n",
    "Print the descriptive statistics of the network: number of nodes, number of edges, number of connected components, radius, diameter, degree distribution.\n",
    "\n",
    "Write a function `desc_stats` that takes in input `url` to file with list of edges and the number of first line `first_line` with an edge. For example, for the file [fb_Princeton.txt](https://raw.githubusercontent.com/vpozdnyakov/network_science_assignments/master/assignment_power_law/fb_Princeton.txt) `first_line=5`. The function should return a dictionary with keys:\n",
    "* `n_nodes`: number of nodes\n",
    "* `n_edges`: number of edges\n",
    "* `n_connected_components`: number of connected components\n",
    "* `radius`: radius of the giant component\n",
    "* `diameter`: diameter of the giant component\n",
    "* `degree_sequence`: np.array of node degrees of the giant component\n",
    "\n",
    "*Hints:* \n",
    "1. *To load the network use `np.loadtxt(url)`*\n",
    "2. *To speed up the calculation of a radius and diameter, use the stochastic estimation: take into account only random 5% eccentricities*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e7df5f2eb4b4cdf6eb35b47274c97b67",
     "grade": false,
     "grade_id": "cell-a9e936f57320e3a5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def desc_stats(url, first_line=1, random_seed=1):\n",
    "    '''Calculate descriptive statistics of a network.'''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ec8317301431544079c8540bdf6939f",
     "grade": true,
     "grade_id": "cell-5c6e9df19540c451",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''Check statistics of the network'''\n",
    "url = 'https://raw.githubusercontent.com/vpozdnyakov/network_science_assignments/master/assignment_power_law/fb_Princeton.txt'\n",
    "fb_stats = desc_stats(url, 5)\n",
    "assert fb_stats['n_nodes'] == 6596"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us draw the node degree distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = np.bincount(fb_stats['degree_sequence'])\n",
    "idx = np.argwhere(hist > 0)\n",
    "plt.scatter(idx, hist[idx], s=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6. Maximum likelihood estimation of Power law (2 points)\n",
    "\n",
    "Let us estimate $\\alpha$ and $x_\\min$ of Princeton network using maximum likelihood. The algorithm consists of:\n",
    "1. Fix $x_\\min$ as a minimal node degree\n",
    "2. Calculate $\\alpha$ via maximum likelihood estimation using fixed $x_\\min$\n",
    "3. Calculate Kolmogorov-Smirnov test\n",
    "4. Fix $x_\\min$ as the next node degree\n",
    "5. Repeat 2-4 by scanning all possible $x_\\min$ and find the best $\\alpha$ and $x_\\min$ with respect to Kolmogorov-Smirnov test\n",
    "\n",
    "Write a function `ml_power_law_params` that takes as input node degree sequence `degree_sequence` and returns a tuple of two values: the best $\\alpha$ and $x_\\min$.\n",
    "\n",
    "*Hints:*\n",
    "1. *Do not forget to drop node degrees that less than $x_\\min$ in each iteration*\n",
    "2. *To calculate Kolmogorov-Smirnov distance use `scipy.stats.kstest`*\n",
    "3. *Look at details in http://networksciencebook.com/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b1a0d4fbfd77625ef2de73ab0a3152b",
     "grade": false,
     "grade_id": "cell-1c3f80ba088eaad3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ml_power_law_params(degree_sequence):\n",
    "    '''Estimate alpha and x_min via maximum lokelihood'''\n",
    "    best_alpha, best_x_min = None, None\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return best_alpha, best_x_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ecd34988200528ebe75d4e359f4a0a2",
     "grade": true,
     "grade_id": "cell-f44b36a581ebe30d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''Check the estimation of Power law parameters'''\n",
    "alpha, x_min = 3.5, 1\n",
    "hat_alpha, hat_x_min = ml_power_law_params(power_law_generate(20000, alpha, x_min))\n",
    "assert round(hat_alpha, 1) == alpha and round(hat_x_min, 1) == x_min\n",
    "alpha, x_min = 7, 1\n",
    "hat_alpha, hat_x_min = ml_power_law_params(power_law_generate(20000, alpha, x_min))\n",
    "assert round(hat_alpha, 1) == alpha and round(hat_x_min, 1) == x_min\n",
    "alpha, x_min = 10, 3\n",
    "hat_alpha, hat_x_min = ml_power_law_params(power_law_generate(20000, alpha, x_min))\n",
    "assert round(hat_alpha, 1) == alpha and round(hat_x_min, 1) == x_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us draw the estimated PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_sequence = fb_stats['degree_sequence']\n",
    "best_alpha, best_x_min = ml_power_law_params(degree_sequence)\n",
    "\n",
    "hist, bin_edges = np.histogram(\n",
    "    degree_sequence[degree_sequence > best_x_min], \n",
    "    bins=100, \n",
    "    density=True)\n",
    "bin_centers = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "idx = hist > 0\n",
    "plt.scatter(bin_centers[idx], hist[idx], s=5)\n",
    "x_space = np.linspace(best_x_min, fb_stats['degree_sequence'].max(), 100)\n",
    "plt.plot(\n",
    "    x_space, \n",
    "    power_law_pdf(x_space, best_alpha, best_x_min), \n",
    "    color='tab:orange', \n",
    "    label='Estimated PDF')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
